In his article, _The Problem With Counterfeit People_ Daniel Dennett examines the ethical dilemma of regulating the use of AI to prevent the creation of fake people and identities. He likens this crime to the seriousness with which counterfeiting was treated in the early days of human society - something dangerous enough to warrant the most severe punishment as a deterrent. While the passing of a computer as a human being began as an intellectual exercise - known by many as the Turing Test, it has swiftly evolved into something that could threaten our freedom and democracy.
Dennett warns of the danger these artificial people can create through the spread of misinformation. Information - specifically trustworthy information is the basis of a democratic society. Dennett examines the threat of counterfeit digital people to the informed consent of the governed. Consulting with other humans to make decisions is the very core of human society. However, when those who appear to be honest members of our community are really digital counterfeits in disguise, it becomes much easier for the powerful and wealthy few to manipulate society. 
The danger of these counterfeit people is magnified by the fact that all that is needed to create them is a computer. With today's access to information, it becomes much easier for anyone to make these counterfeit people and for them to evolve and multiply in the digital world almost without limit.
After painting this terrifying future, Dennett moves on to discuss how we can save ourselves from this fate. His answer: imposing the harshest liability on AI companies, their technicians, and their executives for any misuse of their technology. He even suggests life imprisonment as the most appropriate punishment.
Dennett believes that we should impose strict measures, similar to those used by scanners that are programmed to prevent counterfeiting of currency. In fact, Dennett suggests making such measures a legal requirement - limiting room for even the most wealthy to bend the rules. As a big motivator for companies is their profit margins, he also suggests fines to ensure cooperation.
He makes the argument for AI companies, such as Google and OpenAi to be held liable for any misuse of their products. While, in an ideal world this would be a good solution, this would realistically create a huge and unreasonable burden on the companies. It is impossible to blame companies for any misuse of their products because, with some creativity, it would be possible to "misuse" any AI product. It just would not be possible to place enough safety measures without significantly compromising functionality.
Seemingly in recognition of this practical flaw, Dennett ends his piece by placing a strong emphasis on the individual ethical responsibility of engineers to be proactive in preventing the creation of counterfeit people. He warns that this danger directly impacts not just society as a whole, but also the individual freedom of the programer's loved ones, using this personal appeal to make the risk feel more palpable. Having both negative legal consequences and social repercussions would be key to ensuring regulation.
